{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hugging face peft\n",
    "\n",
    "## /conceptual_guides/prompting\n",
    "* https://huggingface.co/docs/peft/conceptual_guides/prompting\n",
    "* 三个例子 to_read.\n",
    "  * https://huggingface.co/docs/peft/task_guides/clm-prompt-tuning\n",
    "  * https://huggingface.co/docs/peft/task_guides/seq2seq-prefix-tuning\n",
    "  * https://huggingface.co/docs/peft/task_guides/ptuning-seq-classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# paddlenlp prompt\n",
    "\n",
    "## MLMPromptTokenizer class\n",
    "\"\"\"\n",
    "tokenizer enter [{'text': '[MASK]', 'do_truncate': False, 'token_types': 0, 'positions': -1, 'soft_tokens': None, 'encoder_ids': 0}, {'text': ['[UNK]'], 'do_truncate': False, 'token_types': 0, 'positions': -1, 'soft_tokens': [1], 'encoder_ids': 0}, {'text': '耳机不错，颜值很高，唯一缺点是戴上 听诊器效应 很严重。', 'do_truncate': True, 'token_types': 0, 'positions': -1, 'soft_tokens': None, 'encoder_ids': 0}]\n",
    "\n",
    "tokenizer finish defaultdict(<class 'list'>, {'soft_token_ids': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [1, 3, 1, 1228, 98, 16, 990, 4, 1258, 552, 321, 69, 4, 1239, 7, 1009, 180, 10, 1616, 28, 818, 1395, 361, 344, 149, 321, 678, 118, 12043, 2], 'position_ids': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'encoder_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'masked_positions': [1]})\n",
    "\"\"\"\n",
    "\n",
    "* soft_token_ids: soft prompt token 在哪一位上； 'input_ids': [1, 3' --> [CLS] ['MASK'] 所以是第三位。2] --> ['SEP']\n",
    "* p-tuning 用此tokenizer，以上为tokenized的结果\n",
    "\n",
    "\n",
    "## SoftTemplate\n",
    "* 此类中实现 soft token 查embedding： process_batch-->input_dict[\"inputs_embeds\"] = paddle.where(soft_token_ids > 0, soft_embeds, word_embeds), 并删除input_dict 中\"inputs_ids\"这样可以实现 soft token查soft_embeds, 而其它token查plm 中的word_embeds.\n",
    "* 如何自定义模板\n",
    "  * https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/advanced_guide/prompt.md#%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E6%A8%A1%E6%9D%BF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
