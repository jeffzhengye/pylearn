{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tutorials\n",
    "\n",
    "* https://zhuanlan.zhihu.com/p/676635585\n",
    "\n",
    "# supported models\n",
    "\n",
    "* https://docs.vllm.ai/en/latest/models/supported_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use modelscope model\n",
    "\n",
    "* export VLLM_USE_MODELSCOPE=True\n",
    "\n",
    "```python\n",
    "from vllm import LLM\n",
    "\n",
    "llm = LLM(model=..., revision=..., trust_remote_code=True)  # Name or path of your model\n",
    "output = llm.generate(\"Hello, my name is\")\n",
    "print(output)\n",
    "```\n",
    "* example:\n",
    "```python\n",
    "llm = LLM(model=\"shakechen/Llama-2-7b-hf\", revision=\"master\", trust_remote_code=True)\n",
    "prompts = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "prompts = [\"帮我写一篇介绍董晓蕊的文章\", \"曹操为什么赤壁之战中会失败？\"]\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95)\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "# Print the outputs.\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# serving with openai and modelscope\n",
    "\n",
    "## start serving\n",
    "* VLLM_USE_MODELSCOPE=True python -m vllm.entrypoints.openai.api_server --model=\"qwen/Qwen-14B-Chat\" --revision=\"v1.0.1\" --trust-remote-code\n",
    "\n",
    "## get models \n",
    "\n",
    "* curl http://localhost:8000/v1/models\n",
    "\n",
    "## use openai api -chat example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from openai import ChatCompletion\n",
    "# Set OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://59.68.29.90:17900/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "print('current model:', model)\n",
    "chat_response = client.chat.completions.create(\n",
    "    # model=\"qwen/Qwen-14B-Chat\",\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    ]\n",
    ")\n",
    "print(\"Chat response:\", chat_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## completion example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion results:\n",
      "Completion(id='cmpl-c3fca6584ef943f2b831df0b45e9aa45', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=Logprobs(text_offset=[0, 3, 4, 12, 15, 21, 22, 28, 30, 36, 42, 45, 50, 53, 58, 60], token_logprobs=[-0.14477035403251648, -0.013734362088143826, -0.0006811682251282036, -0.013870514929294586, -0.0010487301042303443, -0.001557805109769106, -0.014080584980547428, -0.000674616196192801, -0.0003554189461283386, -0.003102491609752178, -0.001405324088409543, -0.00017832119192462415, -0.0006668727728538215, -0.0008133916999213398, -0.5331632494926453, -0.5901650190353394], tokens=[' or', ',', ' through', ' in', 'action', ',', ' allow', ' a', ' human', ' being', ' to', ' come', ' to', ' harm', '.\\n', 'A'], top_logprobs=[{' or': -0.14477035403251648, ',': -2.144770383834839, '.\\n': -5.51977014541626}, {',': -0.013734362088143826, ' through': -4.826234340667725, ' allow': -6.388734340667725}, {' through': -0.0006811682251282036, ' Through': -8.125680923461914, 'through': -8.750680923461914}, {' in': -0.013870514929294586, ' its': -5.013870716094971, ' lack': -5.951370716094971}, {'action': -0.0010487301042303443, ' action': -7.688548564910889, 'activity': -8.376049041748047}, {',': -0.001557805109769106, ',\\n': -8.376557350158691, ' allow': -8.814057350158691}, {' allow': -0.014080584980547428, ' permit': -4.38908052444458, ' expose': -7.88908052444458}, {' a': -0.000674616196192801, ' such': -8.8131742477417, ' the': -9.0631742477417}, {' human': -0.0003554189461283386, 'human': -9.00035572052002, ' person': -9.93785572052002}, {' being': -0.003102491609752178, ' to': -6.5656023025512695, ' beings': -7.4406023025512695}, {' to': -0.001405324088409543, ' ': -7.876405239105225, ' come': -8.813905715942383}, {' come': -0.00017832119192462415, ' be': -9.250178337097168, 'come': -10.125178337097168}, {' to': -0.0006668727728538215, ' harm': -8.375666618347168, '\\n': -9.313166618347168}, {' harm': -0.0008133916999213398, ' physical': -7.5008134841918945, ' injury': -9.563313484191895}, {'.\\n': -0.5331632494926453, '.': -1.53316330909729, '.\\n\\n': -1.84566330909729}, {'A': -0.5901650190353394, 'The': -2.840165138244629, 'This': -3.652665138244629}]), text=' or, through inaction, allow a human being to come to harm.\\nA'), CompletionChoice(finish_reason='length', index=1, logprobs=Logprobs(text_offset=[0, 3, 4, 12, 15, 21, 22, 28, 30, 36, 42, 45, 50, 53, 58, 59], token_logprobs=[-0.14477035403251648, -0.013734362088143826, -0.0006811682251282036, -0.013870514929294586, -0.0010487301042303443, -0.001557805109769106, -0.014080584980547428, -0.000674616196192801, -0.0003554189461283386, -0.003102491609752178, -0.001405324088409543, -0.00017832119192462415, -0.0006668727728538215, -0.0008133916999213398, -1.53316330909729, -7.07761812210083], tokens=[' or', ',', ' through', ' in', 'action', ',', ' allow', ' a', ' human', ' being', ' to', ' come', ' to', ' harm', '.', ' There'], top_logprobs=[{' or': -0.14477035403251648, ',': -2.144770383834839, '.\\n': -5.51977014541626}, {',': -0.013734362088143826, ' through': -4.826234340667725, ' allow': -6.388734340667725}, {' through': -0.0006811682251282036, ' Through': -8.125680923461914, 'through': -8.750680923461914}, {' in': -0.013870514929294586, ' its': -5.013870716094971, ' lack': -5.951370716094971}, {'action': -0.0010487301042303443, ' action': -7.688548564910889, 'activity': -8.376049041748047}, {',': -0.001557805109769106, ',\\n': -8.376557350158691, ' allow': -8.814057350158691}, {' allow': -0.014080584980547428, ' permit': -4.38908052444458, ' expose': -7.88908052444458}, {' a': -0.000674616196192801, ' such': -8.8131742477417, ' the': -9.0631742477417}, {' human': -0.0003554189461283386, 'human': -9.00035572052002, ' person': -9.93785572052002}, {' being': -0.003102491609752178, ' to': -6.5656023025512695, ' beings': -7.4406023025512695}, {' to': -0.001405324088409543, ' ': -7.876405239105225, ' come': -8.813905715942383}, {' come': -0.00017832119192462415, ' be': -9.250178337097168, 'come': -10.125178337097168}, {' to': -0.0006668727728538215, ' harm': -8.375666618347168, '\\n': -9.313166618347168}, {' harm': -0.0008133916999213398, ' physical': -7.5008134841918945, ' injury': -9.563313484191895}, {'.': -1.53316330909729, '.\\n': -0.5331632494926453, '.\\n\\n': -1.84566330909729}, {' There': -7.07761812210083, ' Translate': -1.23386812210083, ' A': -1.79636812210083, ' It': -2.79636812210083}]), text=' or, through inaction, allow a human being to come to harm. There')], created=5315151, model='qwen/Qwen-14B-Chat', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=32, prompt_tokens=9, total_tokens=41))\n"
     ]
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "model = models.data[0].id\n",
    "\n",
    "# Completion API\n",
    "stream = False\n",
    "completion = client.completions.create(\n",
    "    model=model,\n",
    "    prompt=\"A robot may not injure a human being\",\n",
    "    echo=False,\n",
    "    n=2,\n",
    "    stream=stream,\n",
    "    logprobs=3\n",
    ")\n",
    "\n",
    "print(\"Completion results:\")\n",
    "if stream:\n",
    "    for c in completion:\n",
    "        print(c)\n",
    "else:\n",
    "    print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
