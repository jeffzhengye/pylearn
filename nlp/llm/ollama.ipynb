{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linux install\n",
    "\n",
    "* curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# start service\n",
    "\n",
    "* ollama serve\n",
    "\n",
    "# stop \n",
    "\n",
    "* sudo systemctl stop ollama.service\n",
    "\n",
    "# disable it if you want\n",
    "* systemctl disable ollama.service\n",
    "\n",
    "# confirm its status\n",
    "* systemctl status ollama.service\n",
    "\n",
    "# list models \n",
    "\n",
    "* ollama list\n",
    "\n",
    "# run model\n",
    "\n",
    "* ollama run llama2\n",
    "* ollama run qwen2:0.5b # with a specific version.\n",
    "* ollama run qwen2:0.5b --stream\n",
    "* more models supported and docs here: https://ollama.com/library\n",
    "\n",
    "# keep alive 常驻内存等环境变量\n",
    "\n",
    "Environment=\"CUDA_VISIBLE_DEVICES=0,1\" 代表让ollama能识别到第几张显卡\n",
    "Environment=\"OLLAMA_SCHED_SPREAD=1\" 这几张卡均衡使用\n",
    "Environment=\"OLLAMA_KEEP_ALIVE=-1\" 模型一直加载, 不自动卸载\n",
    "Environment=\"OLLAMA_HOST=0.0.0.0\" 监听地址\n",
    "Environment=\"OLLAMA_PORT=11434\" 监听端口\n",
    "\n",
    "# docs \n",
    "\n",
    "* https://ollama.ai/docs\n",
    "\n",
    "\n",
    "## api\n",
    "\n",
    "* https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "* 启动默认地址：The Ollama API is now available at 127.0.0.1:11434."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ollama alternatives\n",
    "\n",
    "## LocalAI\n",
    "\n",
    "* 23.5k stars\n",
    "* No GPU required. Drop-in replacement for OpenAI, running on consumer-grade hardware.\n",
    "\n",
    "## Xorbits inference\n",
    "\n",
    "* 4.9k stars\n",
    "* designed to serve language, speech recognition, and multimodal models.\n",
    "* support speech, qwen2-audio, image generation, text embedding, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trouble shooting\n",
    "\n",
    "## CUDA error: CUBLAS_STATUS_NOT_SUPPORTED\n",
    "\n",
    "* sudo apt install nvidia-cuda-toolkit"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
