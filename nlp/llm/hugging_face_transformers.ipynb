{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tutorial\n",
    "* https://xiaosheng.run/2021/12/08/transformers-note-1.html 小昇的博客 \n",
    "* [The Transformer model family - huggingface](https://huggingface.co/docs/transformers/model_summary)\n",
    "* https://paddlepedia.readthedocs.io/en/latest/tutorials/pretrain_model/pretrain_model_description.html\n",
    "\n",
    "\n",
    "## 如何向 Transformers 模型词表中添加新 token\n",
    "\n",
    "* https://xiaosheng.run/2023/01/07/add-new-token.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "model_name_or_path = \"bigscience/mt0-large\"\n",
    "tokenizer_name_or_path = \"bigscience/mt0-large\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download models from huggingface\n",
    "\n",
    "* git lfs install\n",
    "* git clone git@hf.co:<MODEL ID> # example: git clone git@hf.co:bigscience/bloom\n",
    "* https://huggingface.co/docs/hub/models-downloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment variables\n",
    "\n",
    "* docs: https://huggingface.co/docs/huggingface_hub/package_reference/environment_variables\n",
    "\n",
    "## HF_HOME\n",
    "\n",
    "* To configure where huggingface_hub will locally store data. In particular, your token and the cache will be stored in this folder. Defaults to \"~/.cache/huggingface\" unless XDG_CACHE_HOME is set\n",
    "\n",
    "## HF_ENDPOINT\n",
    "\n",
    "* where to download models, datasets and spaces. Defaults to \"https://huggingface.co\", \n",
    "* change to https://hf-mirror.com for Chinese users.\n",
    "\n",
    "## HF_HUB_CACHE\n",
    "\n",
    "* To configure where repositories from the Hub will be cached locally (models, datasets and spaces).\n",
    "\n",
    "Defaults to \"$HF_HOME/hub\" (e.g. \"~/.cache/huggingface/hub\" by default).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
