{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tutorial\n",
    "\n",
    "* github: https://github.com/coqui-ai/TTS/\n",
    "* https://tts.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for 🐸Coqui Studio voices - https://coqui.ai \n",
      "Visit 🔗https://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tts_models/multilingual/multi-dataset/your_tts',\n",
       " 'tts_models/bg/cv/vits',\n",
       " 'tts_models/cs/cv/vits',\n",
       " 'tts_models/da/cv/vits',\n",
       " 'tts_models/et/cv/vits',\n",
       " 'tts_models/ga/cv/vits',\n",
       " 'tts_models/en/ek1/tacotron2',\n",
       " 'tts_models/en/ljspeech/tacotron2-DDC',\n",
       " 'tts_models/en/ljspeech/tacotron2-DDC_ph',\n",
       " 'tts_models/en/ljspeech/glow-tts',\n",
       " 'tts_models/en/ljspeech/speedy-speech',\n",
       " 'tts_models/en/ljspeech/tacotron2-DCA',\n",
       " 'tts_models/en/ljspeech/vits',\n",
       " 'tts_models/en/ljspeech/vits--neon',\n",
       " 'tts_models/en/ljspeech/fast_pitch',\n",
       " 'tts_models/en/ljspeech/overflow',\n",
       " 'tts_models/en/ljspeech/neural_hmm',\n",
       " 'tts_models/en/vctk/vits',\n",
       " 'tts_models/en/vctk/fast_pitch',\n",
       " 'tts_models/en/sam/tacotron-DDC',\n",
       " 'tts_models/en/blizzard2013/capacitron-t2-c50',\n",
       " 'tts_models/en/blizzard2013/capacitron-t2-c150_v2',\n",
       " 'tts_models/en/multi-dataset/tortoise-v2',\n",
       " 'tts_models/en/jenny/jenny',\n",
       " 'tts_models/es/mai/tacotron2-DDC',\n",
       " 'tts_models/es/css10/vits',\n",
       " 'tts_models/fr/mai/tacotron2-DDC',\n",
       " 'tts_models/fr/css10/vits',\n",
       " 'tts_models/uk/mai/glow-tts',\n",
       " 'tts_models/uk/mai/vits',\n",
       " 'tts_models/zh-CN/baker/tacotron2-DDC-GST',\n",
       " 'tts_models/nl/mai/tacotron2-DDC',\n",
       " 'tts_models/nl/css10/vits',\n",
       " 'tts_models/de/thorsten/tacotron2-DCA',\n",
       " 'tts_models/de/thorsten/vits',\n",
       " 'tts_models/de/thorsten/tacotron2-DDC',\n",
       " 'tts_models/de/css10/vits-neon',\n",
       " 'tts_models/ja/kokoro/tacotron2-DDC',\n",
       " 'tts_models/tr/common-voice/glow-tts',\n",
       " 'tts_models/it/mai_female/glow-tts',\n",
       " 'tts_models/it/mai_female/vits',\n",
       " 'tts_models/it/mai_male/glow-tts',\n",
       " 'tts_models/it/mai_male/vits',\n",
       " 'tts_models/ewe/openbible/vits',\n",
       " 'tts_models/hau/openbible/vits',\n",
       " 'tts_models/lin/openbible/vits',\n",
       " 'tts_models/tw_akuapem/openbible/vits',\n",
       " 'tts_models/tw_asante/openbible/vits',\n",
       " 'tts_models/yor/openbible/vits',\n",
       " 'tts_models/hu/css10/vits',\n",
       " 'tts_models/el/cv/vits',\n",
       " 'tts_models/fi/css10/vits',\n",
       " 'tts_models/hr/cv/vits',\n",
       " 'tts_models/lt/cv/vits',\n",
       " 'tts_models/lv/cv/vits',\n",
       " 'tts_models/mt/cv/vits',\n",
       " 'tts_models/pl/mai_female/vits',\n",
       " 'tts_models/pt/cv/vits',\n",
       " 'tts_models/ro/cv/vits',\n",
       " 'tts_models/sk/cv/vits',\n",
       " 'tts_models/sl/cv/vits',\n",
       " 'tts_models/sv/cv/vits',\n",
       " 'tts_models/ca/custom/vits',\n",
       " 'tts_models/fa/custom/glow-tts',\n",
       " 'tts_models/bn/custom/vits-male',\n",
       " 'tts_models/bn/custom/vits-female']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "# Running a multi-speaker and multi-lingual model\n",
    "\n",
    "# List available 🐸TTS models and choose the first one\n",
    "# model_name = TTS.list_models()[0]\n",
    "# Init TTS\n",
    "# tts = TTS(model_name)\n",
    "\n",
    "TTS.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/zh-CN/baker/tacotron2-DDC-GST is already downloaded.\n",
      " > Using model: tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:C:\\Users\\73915\\AppData\\Local\\tts\\tts_models--zh-CN--baker--tacotron2-DDC-GST\\scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH=\"coqui.wav\"\n",
    "tts = TTS(model_name=\"tts_models/zh-CN/baker/tacotron2-DDC-GST\", progress_bar=False, gpu=True)\n",
    "# Run TTS\n",
    "# tts.tts_to_file(text=\"Ich bin eine Testnachricht.\", file_path=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['今天的最低气温达到零下十度了吗，come on CEO？']\n",
      "dʑin1tiɛn1 dø5 dzuei4di1tɕi4wœn1 da2daʌ4 lɨŋ2ɕia4 ʂʏ2du4 lø5 ma5 ， come   on   CEO ？\n",
      " [!] Character 'C' not found in the vocabulary. Discarding it.\n",
      "dʑin1tiɛn1 dø5 dzuei4di1tɕi4wœn1 da2daʌ4 lɨŋ2ɕia4 ʂʏ2du4 lø5 ma5 ， come   on   CEO ？\n",
      " [!] Character 'E' not found in the vocabulary. Discarding it.\n",
      "dʑin1tiɛn1 dø5 dzuei4di1tɕi4wœn1 da2daʌ4 lɨŋ2ɕia4 ʂʏ2du4 lø5 ma5 ， come   on   CEO ？\n",
      " [!] Character 'O' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 3.188436985015869\n",
      " > Real-time factor: 0.7113590286506386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'coqui.wav'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 中文必须以中文标点如?结束，否则有bug。 \n",
    "\n",
    "tts.tts_to_file(text=\"今天的最低气温达到零下十度了吗，come on CEO？\", file_path=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi\n",
    "from TTS.api import TTS\n",
    "OUTPUT_PATH=\"coqui_multi.wav\"\n",
    "tts_models/en/ljspeech/tacotron2-DDC_ph\n",
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\", progress_bar=True, gpu=True)\n",
    "# tts.tts_to_file(text=\"今天的最低气温达到零下十度了吗，come on CEO？\",  speaker=tts.speakers[0], language=tts.languages[0], file_path=OUTPUT_PATH)\n",
    "\n",
    "tts.tts_to_file(text=\"hello everybody，this is zheng ye from scuec. Come on CEO？\",  speaker=tts.speakers[0], language=tts.languages[0], file_path=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker=female-en-5\n",
      " > Text splitted to sentences.\n",
      "['hello everybody，this is zheng ye from scuec.', 'Come on CEO？']\n",
      " > Processing time: 0.39876484870910645\n",
      " > Real-time factor: 0.07392748400242982\n",
      "speaker=female-en-5\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['hello everybody，this is zheng ye from scuec.', 'Come on CEO？']\n",
      " > Processing time: 0.24767160415649414\n",
      " > Real-time factor: 0.04927807484211981\n",
      "speaker=female-pt-4\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['hello everybody，this is zheng ye from scuec.', 'Come on CEO？']\n",
      " > Processing time: 0.360034704208374\n",
      " > Real-time factor: 0.06283328171175812\n",
      "speaker=male-en-2\n",
      " > Text splitted to sentences.\n",
      "['hello everybody，this is zheng ye from scuec.', 'Come on CEO？']\n",
      " > Processing time: 0.353687047958374\n",
      " > Real-time factor: 0.0812326706381199\n",
      "speaker=male-en-2\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['hello everybody，this is zheng ye from scuec.', 'Come on CEO？']\n",
      " > Processing time: 0.36759376525878906\n",
      " > Real-time factor: 0.08057732688706468\n",
      "speaker=male-pt-3\n",
      "\n",
      " > Text splitted to sentences.\n",
      "['hello everybody，this is zheng ye from scuec.', 'Come on CEO？']\n",
      " > Processing time: 0.3562307357788086\n",
      " > Real-time factor: 0.07468149597040014\n"
     ]
    }
   ],
   "source": [
    "for i, speaker in enumerate(tts.speakers):\n",
    "    speaker_path = speaker.split(\"\\\\\")[0]\n",
    "    print(f\"speaker={speaker}\")\n",
    "    OUTPUT_PATH = f\"coqui_{i}.wav\"\n",
    "    tts.tts_to_file(text=\"hello everybody，this is zheng ye from scuec. Come on CEO？\",  speaker=speaker, language=tts.languages[0], file_path=OUTPUT_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi\n",
    "from TTS.api import TTS\n",
    "OUTPUT_PATH=\"coqui_en.wav\"\n",
    "model_name = \"tts_models/en/ljspeech/tacotron2-DDC_ph\"\n",
    "tts = TTS(model_name=model_name, progress_bar=True, gpu=True)\n",
    "# tts.tts_to_file(text=\"今天的最低气温达到零下十度了吗，come on CEO？\",  speaker=tts.speakers[0], language=tts.languages[0], file_path=OUTPUT_PATH)\n",
    "\n",
    "tts.tts_to_file(text=\"hello everybody，this is zheng ye from scuec. Come on, steve is the CEO of Apple. \", file_path=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['hello everybody，this is zheng ye from scuec.', 'Come on, steve is the CEO of Apple.']\n",
      " > Processing time: 1.172119379043579\n",
      " > Real-time factor: 0.20267591207583843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'coqui_en.wav'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts.tts_to_file(text=\"hello everybody，this is zheng ye from scuec. Come on, steve is the CEO of Apple. \", file_path=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\learn\\pylearn\\pybasic\\sound\\coqui_tts.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/learn/pylearn/pybasic/sound/coqui_tts.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mTTS\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m TTS\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/learn/pylearn/pybasic/sound/coqui_tts.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load the model to GPU\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/learn/pylearn/pybasic/sound/coqui_tts.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Bark is really slow on CPU, so we recommend using GPU.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/learn/pylearn/pybasic/sound/coqui_tts.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tts \u001b[39m=\u001b[39m TTS(\u001b[39m\"\u001b[39;49m\u001b[39mtts_models/multilingual/multi-dataset/bark\u001b[39;49m\u001b[39m\"\u001b[39;49m, gpu\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\TTS\\api.py:289\u001b[0m, in \u001b[0;36mTTS.__init__\u001b[1;34m(self, model_name, model_path, config_path, vocoder_path, vocoder_config_path, progress_bar, gpu)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39mif\u001b[39;00m model_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtts_models\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_name \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcoqui_studio\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_name:\n\u001b[1;32m--> 289\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_tts_model_by_name(model_name, gpu)\n\u001b[0;32m    290\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvoice_conversion_models\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_name:\n\u001b[0;32m    291\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_vc_model_by_name(model_name, gpu)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\TTS\\api.py:385\u001b[0m, in \u001b[0;36mTTS.load_tts_model_by_name\u001b[1;34m(self, model_name, gpu)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcsapi \u001b[39m=\u001b[39m CS_API()\n\u001b[0;32m    384\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 385\u001b[0m     model_path, config_path, vocoder_path, vocoder_config_path, model_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_model_by_name(\n\u001b[0;32m    386\u001b[0m         model_name\n\u001b[0;32m    387\u001b[0m     )\n\u001b[0;32m    389\u001b[0m     \u001b[39m# init synthesizer\u001b[39;00m\n\u001b[0;32m    390\u001b[0m     \u001b[39m# None values are fetch from the model\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msynthesizer \u001b[39m=\u001b[39m Synthesizer(\n\u001b[0;32m    392\u001b[0m         tts_checkpoint\u001b[39m=\u001b[39mmodel_path,\n\u001b[0;32m    393\u001b[0m         tts_config_path\u001b[39m=\u001b[39mconfig_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    401\u001b[0m         use_cuda\u001b[39m=\u001b[39mgpu,\n\u001b[0;32m    402\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\TTS\\api.py:348\u001b[0m, in \u001b[0;36mTTS.download_model_by_name\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_model_by_name\u001b[39m(\u001b[39mself\u001b[39m, model_name: \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 348\u001b[0m     model_path, config_path, model_item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmanager\u001b[39m.\u001b[39;49mdownload_model(model_name)\n\u001b[0;32m    349\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfairseq\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m model_name \u001b[39mor\u001b[39;00m (model_item \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(model_item[\u001b[39m\"\u001b[39m\u001b[39mgithub_rls_url\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mlist\u001b[39m)):\n\u001b[0;32m    350\u001b[0m         \u001b[39m# return model directory if there are multiple files\u001b[39;00m\n\u001b[0;32m    351\u001b[0m         \u001b[39m# we assume that the model knows how to load itself\u001b[39;00m\n\u001b[0;32m    352\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, model_path\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\TTS\\utils\\manage.py:287\u001b[0m, in \u001b[0;36mModelManager.download_model\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_model\u001b[39m(\u001b[39mself\u001b[39m, model_name):\n\u001b[0;32m    274\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Download model files given the full model name.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39m    Model name is in the format\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39m        'type/language/dataset/model'\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39m        model_name (str): model name as explained above.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     model_item, model_full_name, model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_model_item(model_name)\n\u001b[0;32m    288\u001b[0m     \u001b[39m# set the model specific output path\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     output_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_prefix, model_full_name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\TTS\\utils\\manage.py:269\u001b[0m, in \u001b[0;36mModelManager._set_model_item\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m    260\u001b[0m     model_item \u001b[39m=\u001b[39m {\n\u001b[0;32m    261\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtts_models\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    262\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlicense\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mCC BY-NC 4.0\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mthis model is released by Meta under Fairseq repo. Visit https://github.com/facebookresearch/fairseq/tree/main/examples/mms for more info.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    266\u001b[0m     }\n\u001b[0;32m    267\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m     \u001b[39m# get model from models.json\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m     model_item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodels_dict[model_type][lang][dataset][model]\n\u001b[0;32m    270\u001b[0m     model_item[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model_type\n\u001b[0;32m    271\u001b[0m \u001b[39mreturn\u001b[39;00m model_item, model_full_name, model\n",
      "\u001b[1;31mKeyError\u001b[0m: 'bark'"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "# Load the model to GPU\n",
    "# Bark is really slow on CPU, so we recommend using GPU.\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/bark\", gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_editor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
